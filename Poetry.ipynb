{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#tools to help with JSON\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "#pprint - pretty print - preserves formatting\n",
    "from pprint import pprint\n",
    "\n",
    "#urllib / requests - used commonly for apis\n",
    "import requests\n",
    "import urllib2\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import re\n",
    "import HTMLParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###URL = http://www.poetryfoundation.org/poetrymagazine/toc/{#}\n",
    "### 1 through 2472"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listentries = []\n",
    "for issue in range(2299,2473):\n",
    "        url = \"http://www.poetryfoundation.org/poetrymagazine/toc/\" + str(issue)\n",
    "        urlnum = issue\n",
    "        try:\n",
    "            page = urllib2.urlopen(url)\n",
    "            soup = BeautifulSoup(page.read())\n",
    "            issue = re.sub(' : Poetry Magazine', '', soup.title.string)\n",
    "            x = soup.find_all('div', class_ = 'item')\n",
    "            #print (issue, len(x))\n",
    "            for i in range(0,len(x)):\n",
    "                poet = x[i].find_all('span', class_='author')\n",
    "                poetname = poet[0].get_text()\n",
    "                y = x[i].find_all('a', href=re.compile('.*/poem/.*'))\n",
    "                for i in y:\n",
    "                    poemtitle = i.get_text().encode('ascii','ignore')\n",
    "                    poemurl = 'http://www.poetryfoundation.org' + i.get('href')\n",
    "                    poetname = poetname.encode('ascii', 'ignore')\n",
    "                    issue = re.sub(' : Poetry Magazine', '', issue).encode('ascii', 'ignore')\n",
    "                    \n",
    "                    \n",
    "                    dict1 = {'IssueUrl': urlnum, 'Issue': issue, 'PoetName': poetname, 'PoemTitle': poemtitle, 'PoemUrl': poemurl }\n",
    "                    listentries.append(dict1)\n",
    "        except Exception: \n",
    "            pass\n",
    "\n",
    "#                 print (issue, poetname, poemtitle, poemurl)  \n",
    "\n",
    "pmagdf = pd.DataFrame(listentries) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pmagdf.IssueUrl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('output.xlsx')\n",
    "pmagdf.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/bio/michael-hudson'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.poetryfoundation.org/poetrymagazine/poem/250038\"\n",
    "page = urllib2.urlopen(url)\n",
    "soup = BeautifulSoup(page.read())\n",
    "link = soup.find('a', href= re.compile('.*/bio/.*'))\n",
    "link.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pmagdf.PoetName.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://www.poetryfoundation.org/bio/jennifer-tamayo#poet\"\n",
    "page = urllib2.urlopen(url)\n",
    "soup = BeautifulSoup(page.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"text\"><a href=\"/browse/poets#poet-region=20\">U.S., Mid-Atlantic</a></span>]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('span', class_='text') #poetry foundation tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe to contain the following:\n",
    "### Issue, author, poem, link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1. Data Driven Submissions\n",
    "##2. For writers/poets - can we predict publishability based on gender, race, etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wpage = w.WikipediaPage('Category:21st-century_American_poets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# request=urllib2.Request(\"https://en.wikipedia.org/w/api.php?action=query&titles=List_of_poets&prop=revisions&rvprop=content&format=json\")\n",
    "# response = urllib2.urlopen(request)\n",
    "# elevations = response.read()\n",
    "# wdata = json.loads(elevations)\n",
    "# wdata\n",
    "# wdf = json_normalize(wdata[\"normalized\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
